{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 497.6 MB 363 bytes/s a 0:00:01                    | 22.1 MB 173 kB/s eta 0:45:42     |█▌                              | 23.0 MB 91 kB/s eta 1:26:02.1 MB 91 kB/s eta 1:25:50.9 MB 91 kB/s eta 1:25:09.4 MB 91 kB/s eta 1:24:41388:00     |██▍                             | 37.7 MB 51 kB/s eta 2:27:33 MB 14.2 MB/s eta 0:00:31 |████▉                           | 75.8 MB 12.0 MB/s eta 0:00:36                    | 78.6 MB 3.8 MB/s eta 0:01:49     |█████▊                          | 88.8 MB 3.8 MB/s eta 0:01:47     |██████▌                         | 101.2 MB 8.6 MB/s eta 0:00:4766                | 122.5 MB 7.4 MB/s eta 0:00:51                | 123.8 MB 7.4 MB/s eta 0:00:51172 MB 50 kB/s eta 1:54:28MB/s eta 0:00:27     |███████████                     | 171.7 MB 12.6 MB/s eta 0:00:26      | 175.5 MB 366 kB/s eta 0:14:39      | 176.5 MB 366 kB/s eta 0:14:36��██████▍                    | 177.3 MB 366 kB/s eta 0:14:34      | 178.0 MB 366 kB/s eta 0:14:32      | 180.6 MB 366 kB/s eta 0:14:25107 kB/s eta 0:45:24158 kB/s eta 0:29:37158 kB/s eta 0:29:28158 kB/s eta 0:29:23 kB/s eta 0:29:11�██████████████                | 250.1 MB 335 kB/s eta 0:12:18     |████████████████▎               | 252.6 MB 335 kB/s eta 0:12:10��▍               | 254.6 MB 23.7 MB/s eta 0:00:11     |████████████████▌               | 256.6 MB 23.7 MB/s eta 0:00:11     |█████████████████               | 263.0 MB 23.7 MB/s eta 0:00:10  | 265.8 MB 9.1 MB/s eta 0:00:26��███████▏              | 266.9 MB 9.1 MB/s eta 0:00:26��███████▌              | 271.5 MB 349 kB/s eta 0:10:47�██████▊              | 275.4 MB 349 kB/s eta 0:10:35��███████▉              | 277.1 MB 349 kB/s eta 0:10:31��████████              | 278.6 MB 349 kB/s eta 0:10:26   | 299.4 MB 4.3 MB/s eta 0:00:47��██████████████████▊            | 306.3 MB 305 kB/s eta 0:10:28MB 305 kB/s eta 0:10:27   | 310.5 MB 305 kB/s eta 0:10:14   | 311.4 MB 8.2 MB/s eta 0:00:23�████████▍           | 317.9 MB 127 kB/s eta 0:23:31�████████▊           | 322.9 MB 127 kB/s eta 0:22:51�████████▉           | 324.0 MB 127 kB/s eta 0:22:43�█████████           | 326.0 MB 8.2 MB/s eta 0:00:21�█████████           | 326.8 MB 8.2 MB/s eta 0:00:21�███████████████████▌          | 334.8 MB 5.4 MB/s eta 0:00:30��████████████████████▋          | 336.0 MB 5.4 MB/s eta 0:00:30��█████████████████████          | 343.5 MB 8.6 MB/s eta 0:00:18MB 7.3 MB/s eta 0:00:21MB 7.3 MB/s eta 0:00:20MB 7.3 MB/s eta 0:00:20█████▏        | 360.7 MB 7.6 MB/s eta 0:00:19█████▍        | 363.3 MB 7.6 MB/s eta 0:00:18█████▌        | 364.8 MB 7.6 MB/s eta 0:00:18     |████████████████████████        | 374.2 MB 10.8 MB/s eta 0:00:12�███████████▍       | 379.1 MB 83 kB/s eta 0:23:33�███████████▊       | 385.1 MB 83 kB/s eta 0:22:22██████████▉       | 385.7 MB 83 kB/s eta 0:22:14████████████████████████      | 405.6 MB 83 kB/s eta 0:18:23     |██████████████████████████▏     | 406.3 MB 83 kB/s eta 0:18:14kB/s eta 0:17:46  | 408.8 MB 83 kB/s eta 0:17:44     |██████████████████████████▌     | 412.0 MB 34 kB/s eta 0:41:35kB/s eta 0:40:29     |██████████████████████████▊     | 414.9 MB 34 kB/s eta 0:40:09     |███████████████████████████     | 419.0 MB 1.3 MB/s eta 0:00:59 | 419.3 MB 1.3 MB/s eta 0:00:59 | 419.9 MB 1.3 MB/s eta 0:00:58��███▎    | 424.3 MB 14 kB/s eta 1:24:30     |███████████████████████████▋    | 429.5 MB 14 kB/s eta 1:18:33��███████████████████▎   | 440.2 MB 6.7 MB/s eta 0:00:09     |█████████████████████████████▌  | 458.8 MB 4.7 MB/s eta 0:00:09    |██████████████████████████████  | 467.4 MB 2.6 MB/s eta 0:00:12     |██████████████████████████████▏ | 469.7 MB 3.4 MB/s eta 0:00:09     |██████████████████████████████▎ | 471.5 MB 3.4 MB/s eta 0:00:083 MB 3.9 MB/s eta 0:00:062 MB 3.9 MB/s eta 0:00:05     |███████████████████████████████ | 482.8 MB 8.0 MB/s eta 0:00:02███████▏| 484.6 MB 8.0 MB/s eta 0:00:02███████▎| 486.3 MB 8.0 MB/s eta 0:00:02███████▍| 487.8 MB 8.0 MB/s eta 0:00:02███████▍| 488.8 MB 8.0 MB/s eta 0:00:02�███████▋| 490.9 MB 55.0 MB/s eta 0:00:01��███████████▋| 492.0 MB 55.0 MB/s eta 0:00:01     |███████████████████████████████▊| 492.7 MB 55.0 MB/s eta 0:00:01�██████████▊| 492.8 MB 55.0 MB/s eta 0:00:01��███████████▉| 494.8 MB 55.0 MB/s eta 0:00:01��████████████| 497.2 MB 55.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 4.8 MB/s eta 0:00:01     |█████████████                   | 2.3 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 58 kB/s  eta 0:00:01     |████████████████                | 2.1 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 195 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 4.2 MB/s eta 0:00:01     |██████████████████▍             | 2.6 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 115 kB/s eta 0:00:01███▊                | 7.1 MB 7.0 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorflow) (1.21.2)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 432 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 415 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 4.8 MB/s eta 0:00:01K     |███████████████████████▍        | 3.6 MB 4.8 MB/s eta 0:00:01ta 0:00:01�██████████████████████▎ | 4.6 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 962 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.5.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 417 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/d2l/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 h5py-3.6.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 wrapt-1.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 18:28:25.844701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-13 18:28:25.844776: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# save the final model to file\n",
    "%pip install tensorflow keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 21s 0us/step\n",
      "170508288/170498071 [==============================] - 21s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ 59,  62,  63],\n",
       "          [ 43,  46,  45],\n",
       "          [ 50,  48,  43],\n",
       "          ...,\n",
       "          [158, 132, 108],\n",
       "          [152, 125, 102],\n",
       "          [148, 124, 103]],\n",
       " \n",
       "         [[ 16,  20,  20],\n",
       "          [  0,   0,   0],\n",
       "          [ 18,   8,   0],\n",
       "          ...,\n",
       "          [123,  88,  55],\n",
       "          [119,  83,  50],\n",
       "          [122,  87,  57]],\n",
       " \n",
       "         [[ 25,  24,  21],\n",
       "          [ 16,   7,   0],\n",
       "          [ 49,  27,   8],\n",
       "          ...,\n",
       "          [118,  84,  50],\n",
       "          [120,  84,  50],\n",
       "          [109,  73,  42]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[208, 170,  96],\n",
       "          [201, 153,  34],\n",
       "          [198, 161,  26],\n",
       "          ...,\n",
       "          [160, 133,  70],\n",
       "          [ 56,  31,   7],\n",
       "          [ 53,  34,  20]],\n",
       " \n",
       "         [[180, 139,  96],\n",
       "          [173, 123,  42],\n",
       "          [186, 144,  30],\n",
       "          ...,\n",
       "          [184, 148,  94],\n",
       "          [ 97,  62,  34],\n",
       "          [ 83,  53,  34]],\n",
       " \n",
       "         [[177, 144, 116],\n",
       "          [168, 129,  94],\n",
       "          [179, 142,  87],\n",
       "          ...,\n",
       "          [216, 184, 140],\n",
       "          [151, 118,  84],\n",
       "          [123,  92,  72]]],\n",
       " \n",
       " \n",
       "        [[[154, 177, 187],\n",
       "          [126, 137, 136],\n",
       "          [105, 104,  95],\n",
       "          ...,\n",
       "          [ 91,  95,  71],\n",
       "          [ 87,  90,  71],\n",
       "          [ 79,  81,  70]],\n",
       " \n",
       "         [[140, 160, 169],\n",
       "          [145, 153, 154],\n",
       "          [125, 125, 118],\n",
       "          ...,\n",
       "          [ 96,  99,  78],\n",
       "          [ 77,  80,  62],\n",
       "          [ 71,  73,  61]],\n",
       " \n",
       "         [[140, 155, 164],\n",
       "          [139, 146, 149],\n",
       "          [115, 115, 112],\n",
       "          ...,\n",
       "          [ 79,  82,  64],\n",
       "          [ 68,  70,  55],\n",
       "          [ 67,  69,  55]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[175, 167, 166],\n",
       "          [156, 154, 160],\n",
       "          [154, 160, 170],\n",
       "          ...,\n",
       "          [ 42,  34,  36],\n",
       "          [ 61,  53,  57],\n",
       "          [ 93,  83,  91]],\n",
       " \n",
       "         [[165, 154, 128],\n",
       "          [156, 152, 130],\n",
       "          [159, 161, 142],\n",
       "          ...,\n",
       "          [103,  93,  96],\n",
       "          [123, 114, 120],\n",
       "          [131, 121, 131]],\n",
       " \n",
       "         [[163, 148, 120],\n",
       "          [158, 148, 122],\n",
       "          [163, 156, 133],\n",
       "          ...,\n",
       "          [143, 133, 139],\n",
       "          [143, 134, 142],\n",
       "          [143, 133, 144]]],\n",
       " \n",
       " \n",
       "        [[[255, 255, 255],\n",
       "          [253, 253, 253],\n",
       "          [253, 253, 253],\n",
       "          ...,\n",
       "          [253, 253, 253],\n",
       "          [253, 253, 253],\n",
       "          [253, 253, 253]],\n",
       " \n",
       "         [[255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255],\n",
       "          [255, 255, 255]],\n",
       " \n",
       "         [[255, 255, 255],\n",
       "          [254, 254, 254],\n",
       "          [254, 254, 254],\n",
       "          ...,\n",
       "          [254, 254, 254],\n",
       "          [254, 254, 254],\n",
       "          [254, 254, 254]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[113, 120, 112],\n",
       "          [111, 118, 111],\n",
       "          [105, 112, 106],\n",
       "          ...,\n",
       "          [ 72,  81,  80],\n",
       "          [ 72,  80,  79],\n",
       "          [ 72,  80,  79]],\n",
       " \n",
       "         [[111, 118, 110],\n",
       "          [104, 111, 104],\n",
       "          [ 99, 106,  98],\n",
       "          ...,\n",
       "          [ 68,  75,  73],\n",
       "          [ 70,  76,  75],\n",
       "          [ 78,  84,  82]],\n",
       " \n",
       "         [[106, 113, 105],\n",
       "          [ 99, 106,  98],\n",
       "          [ 95, 102,  94],\n",
       "          ...,\n",
       "          [ 78,  85,  83],\n",
       "          [ 79,  85,  83],\n",
       "          [ 80,  86,  84]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 35, 178, 235],\n",
       "          [ 40, 176, 239],\n",
       "          [ 42, 176, 241],\n",
       "          ...,\n",
       "          [ 99, 177, 219],\n",
       "          [ 79, 147, 197],\n",
       "          [ 89, 148, 189]],\n",
       " \n",
       "         [[ 57, 182, 234],\n",
       "          [ 44, 184, 250],\n",
       "          [ 50, 183, 240],\n",
       "          ...,\n",
       "          [156, 182, 200],\n",
       "          [141, 177, 206],\n",
       "          [116, 149, 175]],\n",
       " \n",
       "         [[ 98, 197, 237],\n",
       "          [ 64, 189, 252],\n",
       "          [ 69, 192, 245],\n",
       "          ...,\n",
       "          [188, 195, 206],\n",
       "          [119, 135, 147],\n",
       "          [ 61,  79,  90]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 73,  79,  77],\n",
       "          [ 53,  63,  68],\n",
       "          [ 54,  68,  80],\n",
       "          ...,\n",
       "          [ 17,  40,  64],\n",
       "          [ 21,  36,  51],\n",
       "          [ 33,  48,  49]],\n",
       " \n",
       "         [[ 61,  68,  75],\n",
       "          [ 55,  70,  86],\n",
       "          [ 57,  79, 103],\n",
       "          ...,\n",
       "          [ 24,  48,  72],\n",
       "          [ 17,  35,  53],\n",
       "          [  7,  23,  32]],\n",
       " \n",
       "         [[ 44,  56,  73],\n",
       "          [ 46,  66,  88],\n",
       "          [ 49,  77, 105],\n",
       "          ...,\n",
       "          [ 27,  52,  77],\n",
       "          [ 21,  43,  66],\n",
       "          [ 12,  31,  50]]],\n",
       " \n",
       " \n",
       "        [[[189, 211, 240],\n",
       "          [186, 208, 236],\n",
       "          [185, 207, 235],\n",
       "          ...,\n",
       "          [175, 195, 224],\n",
       "          [172, 194, 222],\n",
       "          [169, 194, 220]],\n",
       " \n",
       "         [[194, 210, 239],\n",
       "          [191, 207, 236],\n",
       "          [190, 206, 235],\n",
       "          ...,\n",
       "          [173, 192, 220],\n",
       "          [171, 191, 218],\n",
       "          [167, 190, 216]],\n",
       " \n",
       "         [[208, 219, 244],\n",
       "          [205, 216, 240],\n",
       "          [204, 215, 239],\n",
       "          ...,\n",
       "          [175, 191, 217],\n",
       "          [172, 190, 216],\n",
       "          [169, 191, 215]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[207, 199, 181],\n",
       "          [203, 195, 175],\n",
       "          [203, 196, 173],\n",
       "          ...,\n",
       "          [135, 132, 127],\n",
       "          [162, 158, 150],\n",
       "          [168, 163, 151]],\n",
       " \n",
       "         [[198, 190, 170],\n",
       "          [189, 181, 159],\n",
       "          [180, 172, 147],\n",
       "          ...,\n",
       "          [178, 171, 160],\n",
       "          [175, 169, 156],\n",
       "          [175, 169, 154]],\n",
       " \n",
       "         [[198, 189, 173],\n",
       "          [189, 181, 162],\n",
       "          [178, 170, 149],\n",
       "          ...,\n",
       "          [195, 184, 169],\n",
       "          [196, 189, 171],\n",
       "          [195, 190, 171]]],\n",
       " \n",
       " \n",
       "        [[[229, 229, 239],\n",
       "          [236, 237, 247],\n",
       "          [234, 236, 247],\n",
       "          ...,\n",
       "          [217, 219, 233],\n",
       "          [221, 223, 234],\n",
       "          [222, 223, 233]],\n",
       " \n",
       "         [[222, 221, 229],\n",
       "          [239, 239, 249],\n",
       "          [233, 234, 246],\n",
       "          ...,\n",
       "          [223, 223, 236],\n",
       "          [227, 228, 238],\n",
       "          [210, 211, 220]],\n",
       " \n",
       "         [[213, 206, 211],\n",
       "          [234, 232, 239],\n",
       "          [231, 233, 244],\n",
       "          ...,\n",
       "          [220, 220, 232],\n",
       "          [220, 219, 232],\n",
       "          [202, 203, 215]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[150, 143, 135],\n",
       "          [140, 135, 127],\n",
       "          [132, 127, 120],\n",
       "          ...,\n",
       "          [224, 222, 218],\n",
       "          [230, 228, 225],\n",
       "          [241, 241, 238]],\n",
       " \n",
       "         [[137, 132, 126],\n",
       "          [130, 127, 120],\n",
       "          [125, 121, 115],\n",
       "          ...,\n",
       "          [181, 180, 178],\n",
       "          [202, 201, 198],\n",
       "          [212, 211, 207]],\n",
       " \n",
       "         [[122, 119, 114],\n",
       "          [118, 116, 110],\n",
       "          [120, 116, 111],\n",
       "          ...,\n",
       "          [179, 177, 173],\n",
       "          [164, 164, 162],\n",
       "          [163, 163, 161]]]], dtype=uint8),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[[[158, 112,  49],\n",
       "          [159, 111,  47],\n",
       "          [165, 116,  51],\n",
       "          ...,\n",
       "          [137,  95,  36],\n",
       "          [126,  91,  36],\n",
       "          [116,  85,  33]],\n",
       " \n",
       "         [[152, 112,  51],\n",
       "          [151, 110,  40],\n",
       "          [159, 114,  45],\n",
       "          ...,\n",
       "          [136,  95,  31],\n",
       "          [125,  91,  32],\n",
       "          [119,  88,  34]],\n",
       " \n",
       "         [[151, 110,  47],\n",
       "          [151, 109,  33],\n",
       "          [158, 111,  36],\n",
       "          ...,\n",
       "          [139,  98,  34],\n",
       "          [130,  95,  34],\n",
       "          [120,  89,  33]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 68, 124, 177],\n",
       "          [ 42, 100, 148],\n",
       "          [ 31,  88, 137],\n",
       "          ...,\n",
       "          [ 38,  97, 146],\n",
       "          [ 13,  64, 108],\n",
       "          [ 40,  85, 127]],\n",
       " \n",
       "         [[ 61, 116, 168],\n",
       "          [ 49, 102, 148],\n",
       "          [ 35,  85, 132],\n",
       "          ...,\n",
       "          [ 26,  82, 130],\n",
       "          [ 29,  82, 126],\n",
       "          [ 20,  64, 107]],\n",
       " \n",
       "         [[ 54, 107, 160],\n",
       "          [ 56, 105, 149],\n",
       "          [ 45,  89, 132],\n",
       "          ...,\n",
       "          [ 24,  77, 124],\n",
       "          [ 34,  84, 129],\n",
       "          [ 21,  67, 110]]],\n",
       " \n",
       " \n",
       "        [[[235, 235, 235],\n",
       "          [231, 231, 231],\n",
       "          [232, 232, 232],\n",
       "          ...,\n",
       "          [233, 233, 233],\n",
       "          [233, 233, 233],\n",
       "          [232, 232, 232]],\n",
       " \n",
       "         [[238, 238, 238],\n",
       "          [235, 235, 235],\n",
       "          [235, 235, 235],\n",
       "          ...,\n",
       "          [236, 236, 236],\n",
       "          [236, 236, 236],\n",
       "          [235, 235, 235]],\n",
       " \n",
       "         [[237, 237, 237],\n",
       "          [234, 234, 234],\n",
       "          [234, 234, 234],\n",
       "          ...,\n",
       "          [235, 235, 235],\n",
       "          [235, 235, 235],\n",
       "          [234, 234, 234]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 87,  99,  89],\n",
       "          [ 43,  51,  37],\n",
       "          [ 19,  23,  11],\n",
       "          ...,\n",
       "          [169, 184, 179],\n",
       "          [182, 197, 193],\n",
       "          [188, 202, 201]],\n",
       " \n",
       "         [[ 82,  96,  82],\n",
       "          [ 46,  57,  36],\n",
       "          [ 36,  44,  22],\n",
       "          ...,\n",
       "          [174, 189, 183],\n",
       "          [185, 200, 196],\n",
       "          [187, 202, 200]],\n",
       " \n",
       "         [[ 85, 101,  83],\n",
       "          [ 62,  75,  48],\n",
       "          [ 58,  67,  38],\n",
       "          ...,\n",
       "          [168, 183, 178],\n",
       "          [180, 195, 191],\n",
       "          [186, 200, 199]]],\n",
       " \n",
       " \n",
       "        [[[158, 190, 222],\n",
       "          [158, 187, 218],\n",
       "          [139, 166, 194],\n",
       "          ...,\n",
       "          [228, 231, 234],\n",
       "          [237, 239, 243],\n",
       "          [238, 241, 246]],\n",
       " \n",
       "         [[170, 200, 229],\n",
       "          [172, 199, 226],\n",
       "          [151, 176, 201],\n",
       "          ...,\n",
       "          [232, 232, 236],\n",
       "          [246, 246, 250],\n",
       "          [246, 247, 251]],\n",
       " \n",
       "         [[174, 201, 225],\n",
       "          [176, 200, 222],\n",
       "          [157, 179, 199],\n",
       "          ...,\n",
       "          [230, 229, 232],\n",
       "          [250, 249, 251],\n",
       "          [245, 244, 247]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 31,  40,  45],\n",
       "          [ 30,  39,  44],\n",
       "          [ 26,  35,  40],\n",
       "          ...,\n",
       "          [ 37,  40,  46],\n",
       "          [  9,  13,  14],\n",
       "          [  4,   7,   5]],\n",
       " \n",
       "         [[ 23,  34,  39],\n",
       "          [ 27,  38,  43],\n",
       "          [ 25,  36,  41],\n",
       "          ...,\n",
       "          [ 19,  20,  24],\n",
       "          [  4,   6,   3],\n",
       "          [  5,   7,   3]],\n",
       " \n",
       "         [[ 28,  41,  47],\n",
       "          [ 30,  43,  50],\n",
       "          [ 32,  45,  52],\n",
       "          ...,\n",
       "          [  5,   6,   8],\n",
       "          [  4,   5,   3],\n",
       "          [  7,   8,   7]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 20,  15,  12],\n",
       "          [ 19,  14,  11],\n",
       "          [ 15,  14,  11],\n",
       "          ...,\n",
       "          [ 10,   9,   7],\n",
       "          [ 12,  11,   9],\n",
       "          [ 13,  12,  10]],\n",
       " \n",
       "         [[ 21,  16,  13],\n",
       "          [ 20,  16,  13],\n",
       "          [ 18,  17,  12],\n",
       "          ...,\n",
       "          [ 10,   9,   7],\n",
       "          [ 10,   9,   7],\n",
       "          [ 12,  11,   9]],\n",
       " \n",
       "         [[ 21,  16,  13],\n",
       "          [ 21,  17,  12],\n",
       "          [ 20,  18,  11],\n",
       "          ...,\n",
       "          [ 12,  11,   9],\n",
       "          [ 12,  11,   9],\n",
       "          [ 13,  12,  10]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 33,  25,  13],\n",
       "          [ 34,  26,  15],\n",
       "          [ 34,  26,  15],\n",
       "          ...,\n",
       "          [ 28,  25,  52],\n",
       "          [ 29,  25,  58],\n",
       "          [ 23,  20,  42]],\n",
       " \n",
       "         [[ 33,  25,  14],\n",
       "          [ 34,  26,  15],\n",
       "          [ 34,  26,  15],\n",
       "          ...,\n",
       "          [ 27,  24,  52],\n",
       "          [ 27,  24,  56],\n",
       "          [ 25,  22,  47]],\n",
       " \n",
       "         [[ 31,  23,  12],\n",
       "          [ 32,  24,  13],\n",
       "          [ 33,  25,  14],\n",
       "          ...,\n",
       "          [ 24,  23,  50],\n",
       "          [ 26,  23,  53],\n",
       "          [ 25,  20,  47]]],\n",
       " \n",
       " \n",
       "        [[[ 25,  40,  12],\n",
       "          [ 15,  36,   3],\n",
       "          [ 23,  41,  18],\n",
       "          ...,\n",
       "          [ 61,  82,  78],\n",
       "          [ 92, 113, 112],\n",
       "          [ 75,  89,  92]],\n",
       " \n",
       "         [[ 12,  25,   6],\n",
       "          [ 20,  37,   7],\n",
       "          [ 24,  36,  15],\n",
       "          ...,\n",
       "          [115, 134, 138],\n",
       "          [149, 168, 177],\n",
       "          [104, 117, 131]],\n",
       " \n",
       "         [[ 12,  25,  11],\n",
       "          [ 15,  29,   6],\n",
       "          [ 34,  40,  24],\n",
       "          ...,\n",
       "          [154, 172, 182],\n",
       "          [157, 175, 192],\n",
       "          [116, 129, 151]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[100, 129,  81],\n",
       "          [103, 132,  84],\n",
       "          [104, 134,  86],\n",
       "          ...,\n",
       "          [ 97, 128,  84],\n",
       "          [ 98, 126,  84],\n",
       "          [ 91, 121,  79]],\n",
       " \n",
       "         [[103, 132,  83],\n",
       "          [104, 131,  83],\n",
       "          [107, 135,  87],\n",
       "          ...,\n",
       "          [101, 132,  87],\n",
       "          [ 99, 127,  84],\n",
       "          [ 92, 121,  79]],\n",
       " \n",
       "         [[ 95, 126,  78],\n",
       "          [ 95, 123,  76],\n",
       "          [101, 128,  81],\n",
       "          ...,\n",
       "          [ 93, 124,  80],\n",
       "          [ 95, 123,  81],\n",
       "          [ 92, 120,  80]]],\n",
       " \n",
       " \n",
       "        [[[ 73,  78,  75],\n",
       "          [ 98, 103, 113],\n",
       "          [ 99, 106, 114],\n",
       "          ...,\n",
       "          [135, 150, 152],\n",
       "          [135, 149, 154],\n",
       "          [203, 215, 223]],\n",
       " \n",
       "         [[ 69,  73,  70],\n",
       "          [ 84,  89,  97],\n",
       "          [ 68,  75,  81],\n",
       "          ...,\n",
       "          [ 85,  95,  89],\n",
       "          [ 71,  82,  80],\n",
       "          [120, 133, 135]],\n",
       " \n",
       "         [[ 69,  73,  70],\n",
       "          [ 90,  95, 100],\n",
       "          [ 62,  71,  74],\n",
       "          ...,\n",
       "          [ 74,  81,  70],\n",
       "          [ 53,  62,  54],\n",
       "          [ 62,  74,  69]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[123, 128,  96],\n",
       "          [132, 132, 102],\n",
       "          [129, 128, 100],\n",
       "          ...,\n",
       "          [108, 107,  88],\n",
       "          [ 62,  60,  55],\n",
       "          [ 27,  27,  28]],\n",
       " \n",
       "         [[115, 121,  91],\n",
       "          [123, 124,  95],\n",
       "          [129, 126,  99],\n",
       "          ...,\n",
       "          [115, 116,  94],\n",
       "          [ 66,  65,  59],\n",
       "          [ 27,  27,  27]],\n",
       " \n",
       "         [[116, 120,  90],\n",
       "          [121, 122,  94],\n",
       "          [129, 128, 101],\n",
       "          ...,\n",
       "          [116, 115,  94],\n",
       "          [ 68,  65,  58],\n",
       "          [ 27,  26,  26]]]], dtype=uint8),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train and test Cifar10 Dataset\n",
    "def load_dataset():\n",
    "  # load dataset\n",
    "  (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    " \n",
    "  # reshape dataset to have a single channel\n",
    "  # trainX = trainX.reshape((trainX.shape[0], 32, 32, 1))\n",
    "  # testX = testX.reshape((testX.shape[0], 32, 32, 1))\n",
    "\t# one hot encode target values\n",
    "  trainY = to_categorical(trainY)\n",
    "  testY = to_categorical(testY)\n",
    "  return trainX, trainY, testX, testY\n",
    "  \n",
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.23137255, 0.24313726, 0.24705882],\n",
       "          [0.16862746, 0.18039216, 0.1764706 ],\n",
       "          [0.19607843, 0.1882353 , 0.16862746],\n",
       "          ...,\n",
       "          [0.61960787, 0.5176471 , 0.42352942],\n",
       "          [0.59607846, 0.49019608, 0.4       ],\n",
       "          [0.5803922 , 0.4862745 , 0.40392157]],\n",
       " \n",
       "         [[0.0627451 , 0.07843138, 0.07843138],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.07058824, 0.03137255, 0.        ],\n",
       "          ...,\n",
       "          [0.48235294, 0.34509805, 0.21568628],\n",
       "          [0.46666667, 0.3254902 , 0.19607843],\n",
       "          [0.47843137, 0.34117648, 0.22352941]],\n",
       " \n",
       "         [[0.09803922, 0.09411765, 0.08235294],\n",
       "          [0.0627451 , 0.02745098, 0.        ],\n",
       "          [0.19215687, 0.10588235, 0.03137255],\n",
       "          ...,\n",
       "          [0.4627451 , 0.32941177, 0.19607843],\n",
       "          [0.47058824, 0.32941177, 0.19607843],\n",
       "          [0.42745098, 0.28627452, 0.16470589]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "          [0.7882353 , 0.6       , 0.13333334],\n",
       "          [0.7764706 , 0.6313726 , 0.10196079],\n",
       "          ...,\n",
       "          [0.627451  , 0.52156866, 0.27450982],\n",
       "          [0.21960784, 0.12156863, 0.02745098],\n",
       "          [0.20784314, 0.13333334, 0.07843138]],\n",
       " \n",
       "         [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "          [0.6784314 , 0.48235294, 0.16470589],\n",
       "          [0.7294118 , 0.5647059 , 0.11764706],\n",
       "          ...,\n",
       "          [0.72156864, 0.5803922 , 0.36862746],\n",
       "          [0.38039216, 0.24313726, 0.13333334],\n",
       "          [0.3254902 , 0.20784314, 0.13333334]],\n",
       " \n",
       "         [[0.69411767, 0.5647059 , 0.45490196],\n",
       "          [0.65882355, 0.5058824 , 0.36862746],\n",
       "          [0.7019608 , 0.5568628 , 0.34117648],\n",
       "          ...,\n",
       "          [0.84705883, 0.72156864, 0.54901963],\n",
       "          [0.5921569 , 0.4627451 , 0.32941177],\n",
       "          [0.48235294, 0.36078432, 0.28235295]]],\n",
       " \n",
       " \n",
       "        [[[0.6039216 , 0.69411767, 0.73333335],\n",
       "          [0.49411765, 0.5372549 , 0.53333336],\n",
       "          [0.4117647 , 0.40784314, 0.37254903],\n",
       "          ...,\n",
       "          [0.35686275, 0.37254903, 0.2784314 ],\n",
       "          [0.34117648, 0.3529412 , 0.2784314 ],\n",
       "          [0.30980393, 0.31764707, 0.27450982]],\n",
       " \n",
       "         [[0.54901963, 0.627451  , 0.6627451 ],\n",
       "          [0.5686275 , 0.6       , 0.6039216 ],\n",
       "          [0.49019608, 0.49019608, 0.4627451 ],\n",
       "          ...,\n",
       "          [0.3764706 , 0.3882353 , 0.30588236],\n",
       "          [0.3019608 , 0.3137255 , 0.24313726],\n",
       "          [0.2784314 , 0.28627452, 0.23921569]],\n",
       " \n",
       "         [[0.54901963, 0.60784316, 0.6431373 ],\n",
       "          [0.54509807, 0.57254905, 0.58431375],\n",
       "          [0.4509804 , 0.4509804 , 0.4392157 ],\n",
       "          ...,\n",
       "          [0.30980393, 0.32156864, 0.2509804 ],\n",
       "          [0.26666668, 0.27450982, 0.21568628],\n",
       "          [0.2627451 , 0.27058825, 0.21568628]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.6862745 , 0.654902  , 0.6509804 ],\n",
       "          [0.6117647 , 0.6039216 , 0.627451  ],\n",
       "          [0.6039216 , 0.627451  , 0.6666667 ],\n",
       "          ...,\n",
       "          [0.16470589, 0.13333334, 0.14117648],\n",
       "          [0.23921569, 0.20784314, 0.22352941],\n",
       "          [0.3647059 , 0.3254902 , 0.35686275]],\n",
       " \n",
       "         [[0.64705884, 0.6039216 , 0.5019608 ],\n",
       "          [0.6117647 , 0.59607846, 0.50980395],\n",
       "          [0.62352943, 0.6313726 , 0.5568628 ],\n",
       "          ...,\n",
       "          [0.40392157, 0.3647059 , 0.3764706 ],\n",
       "          [0.48235294, 0.44705883, 0.47058824],\n",
       "          [0.5137255 , 0.4745098 , 0.5137255 ]],\n",
       " \n",
       "         [[0.6392157 , 0.5803922 , 0.47058824],\n",
       "          [0.61960787, 0.5803922 , 0.47843137],\n",
       "          [0.6392157 , 0.6117647 , 0.52156866],\n",
       "          ...,\n",
       "          [0.56078434, 0.52156866, 0.54509807],\n",
       "          [0.56078434, 0.5254902 , 0.5568628 ],\n",
       "          [0.56078434, 0.52156866, 0.5647059 ]]],\n",
       " \n",
       " \n",
       "        [[[1.        , 1.        , 1.        ],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          ...,\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686],\n",
       "          [0.99215686, 0.99215686, 0.99215686]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          ...,\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ],\n",
       "          [1.        , 1.        , 1.        ]],\n",
       " \n",
       "         [[1.        , 1.        , 1.        ],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          ...,\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843],\n",
       "          [0.99607843, 0.99607843, 0.99607843]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.44313726, 0.47058824, 0.4392157 ],\n",
       "          [0.43529412, 0.4627451 , 0.43529412],\n",
       "          [0.4117647 , 0.4392157 , 0.41568628],\n",
       "          ...,\n",
       "          [0.28235295, 0.31764707, 0.3137255 ],\n",
       "          [0.28235295, 0.3137255 , 0.30980393],\n",
       "          [0.28235295, 0.3137255 , 0.30980393]],\n",
       " \n",
       "         [[0.43529412, 0.4627451 , 0.43137255],\n",
       "          [0.40784314, 0.43529412, 0.40784314],\n",
       "          [0.3882353 , 0.41568628, 0.38431373],\n",
       "          ...,\n",
       "          [0.26666668, 0.29411766, 0.28627452],\n",
       "          [0.27450982, 0.29803923, 0.29411766],\n",
       "          [0.30588236, 0.32941177, 0.32156864]],\n",
       " \n",
       "         [[0.41568628, 0.44313726, 0.4117647 ],\n",
       "          [0.3882353 , 0.41568628, 0.38431373],\n",
       "          [0.37254903, 0.4       , 0.36862746],\n",
       "          ...,\n",
       "          [0.30588236, 0.33333334, 0.3254902 ],\n",
       "          [0.30980393, 0.33333334, 0.3254902 ],\n",
       "          [0.3137255 , 0.3372549 , 0.32941177]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.13725491, 0.69803923, 0.92156863],\n",
       "          [0.15686275, 0.6901961 , 0.9372549 ],\n",
       "          [0.16470589, 0.6901961 , 0.94509804],\n",
       "          ...,\n",
       "          [0.3882353 , 0.69411767, 0.85882354],\n",
       "          [0.30980393, 0.5764706 , 0.77254903],\n",
       "          [0.34901962, 0.5803922 , 0.7411765 ]],\n",
       " \n",
       "         [[0.22352941, 0.7137255 , 0.91764706],\n",
       "          [0.17254902, 0.72156864, 0.98039216],\n",
       "          [0.19607843, 0.7176471 , 0.9411765 ],\n",
       "          ...,\n",
       "          [0.6117647 , 0.7137255 , 0.78431374],\n",
       "          [0.5529412 , 0.69411767, 0.80784315],\n",
       "          [0.45490196, 0.58431375, 0.6862745 ]],\n",
       " \n",
       "         [[0.38431373, 0.77254903, 0.92941177],\n",
       "          [0.2509804 , 0.7411765 , 0.9882353 ],\n",
       "          [0.27058825, 0.7529412 , 0.9607843 ],\n",
       "          ...,\n",
       "          [0.7372549 , 0.7647059 , 0.80784315],\n",
       "          [0.46666667, 0.5294118 , 0.5764706 ],\n",
       "          [0.23921569, 0.30980393, 0.3529412 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.28627452, 0.30980393, 0.3019608 ],\n",
       "          [0.20784314, 0.24705882, 0.26666668],\n",
       "          [0.21176471, 0.26666668, 0.3137255 ],\n",
       "          ...,\n",
       "          [0.06666667, 0.15686275, 0.2509804 ],\n",
       "          [0.08235294, 0.14117648, 0.2       ],\n",
       "          [0.12941177, 0.1882353 , 0.19215687]],\n",
       " \n",
       "         [[0.23921569, 0.26666668, 0.29411766],\n",
       "          [0.21568628, 0.27450982, 0.3372549 ],\n",
       "          [0.22352941, 0.30980393, 0.40392157],\n",
       "          ...,\n",
       "          [0.09411765, 0.1882353 , 0.28235295],\n",
       "          [0.06666667, 0.13725491, 0.20784314],\n",
       "          [0.02745098, 0.09019608, 0.1254902 ]],\n",
       " \n",
       "         [[0.17254902, 0.21960784, 0.28627452],\n",
       "          [0.18039216, 0.25882354, 0.34509805],\n",
       "          [0.19215687, 0.3019608 , 0.4117647 ],\n",
       "          ...,\n",
       "          [0.10588235, 0.20392157, 0.3019608 ],\n",
       "          [0.08235294, 0.16862746, 0.25882354],\n",
       "          [0.04705882, 0.12156863, 0.19607843]]],\n",
       " \n",
       " \n",
       "        [[[0.7411765 , 0.827451  , 0.9411765 ],\n",
       "          [0.7294118 , 0.8156863 , 0.9254902 ],\n",
       "          [0.7254902 , 0.8117647 , 0.92156863],\n",
       "          ...,\n",
       "          [0.6862745 , 0.7647059 , 0.8784314 ],\n",
       "          [0.6745098 , 0.7607843 , 0.87058824],\n",
       "          [0.6627451 , 0.7607843 , 0.8627451 ]],\n",
       " \n",
       "         [[0.7607843 , 0.8235294 , 0.9372549 ],\n",
       "          [0.7490196 , 0.8117647 , 0.9254902 ],\n",
       "          [0.74509805, 0.80784315, 0.92156863],\n",
       "          ...,\n",
       "          [0.6784314 , 0.7529412 , 0.8627451 ],\n",
       "          [0.67058825, 0.7490196 , 0.85490197],\n",
       "          [0.654902  , 0.74509805, 0.84705883]],\n",
       " \n",
       "         [[0.8156863 , 0.85882354, 0.95686275],\n",
       "          [0.8039216 , 0.84705883, 0.9411765 ],\n",
       "          [0.8       , 0.84313726, 0.9372549 ],\n",
       "          ...,\n",
       "          [0.6862745 , 0.7490196 , 0.8509804 ],\n",
       "          [0.6745098 , 0.74509805, 0.84705883],\n",
       "          [0.6627451 , 0.7490196 , 0.84313726]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.8117647 , 0.78039217, 0.70980394],\n",
       "          [0.79607844, 0.7647059 , 0.6862745 ],\n",
       "          [0.79607844, 0.76862746, 0.6784314 ],\n",
       "          ...,\n",
       "          [0.5294118 , 0.5176471 , 0.49803922],\n",
       "          [0.63529414, 0.61960787, 0.5882353 ],\n",
       "          [0.65882355, 0.6392157 , 0.5921569 ]],\n",
       " \n",
       "         [[0.7764706 , 0.74509805, 0.6666667 ],\n",
       "          [0.7411765 , 0.70980394, 0.62352943],\n",
       "          [0.7058824 , 0.6745098 , 0.5764706 ],\n",
       "          ...,\n",
       "          [0.69803923, 0.67058825, 0.627451  ],\n",
       "          [0.6862745 , 0.6627451 , 0.6117647 ],\n",
       "          [0.6862745 , 0.6627451 , 0.6039216 ]],\n",
       " \n",
       "         [[0.7764706 , 0.7411765 , 0.6784314 ],\n",
       "          [0.7411765 , 0.70980394, 0.63529414],\n",
       "          [0.69803923, 0.6666667 , 0.58431375],\n",
       "          ...,\n",
       "          [0.7647059 , 0.72156864, 0.6627451 ],\n",
       "          [0.76862746, 0.7411765 , 0.67058825],\n",
       "          [0.7647059 , 0.74509805, 0.67058825]]],\n",
       " \n",
       " \n",
       "        [[[0.8980392 , 0.8980392 , 0.9372549 ],\n",
       "          [0.9254902 , 0.92941177, 0.96862745],\n",
       "          [0.91764706, 0.9254902 , 0.96862745],\n",
       "          ...,\n",
       "          [0.8509804 , 0.85882354, 0.9137255 ],\n",
       "          [0.8666667 , 0.8745098 , 0.91764706],\n",
       "          [0.87058824, 0.8745098 , 0.9137255 ]],\n",
       " \n",
       "         [[0.87058824, 0.8666667 , 0.8980392 ],\n",
       "          [0.9372549 , 0.9372549 , 0.9764706 ],\n",
       "          [0.9137255 , 0.91764706, 0.9647059 ],\n",
       "          ...,\n",
       "          [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "          [0.8901961 , 0.89411765, 0.93333334],\n",
       "          [0.8235294 , 0.827451  , 0.8627451 ]],\n",
       " \n",
       "         [[0.8352941 , 0.80784315, 0.827451  ],\n",
       "          [0.91764706, 0.9098039 , 0.9372549 ],\n",
       "          [0.90588236, 0.9137255 , 0.95686275],\n",
       "          ...,\n",
       "          [0.8627451 , 0.8627451 , 0.9098039 ],\n",
       "          [0.8627451 , 0.85882354, 0.9098039 ],\n",
       "          [0.7921569 , 0.79607844, 0.84313726]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5882353 , 0.56078434, 0.5294118 ],\n",
       "          [0.54901963, 0.5294118 , 0.49803922],\n",
       "          [0.5176471 , 0.49803922, 0.47058824],\n",
       "          ...,\n",
       "          [0.8784314 , 0.87058824, 0.85490197],\n",
       "          [0.9019608 , 0.89411765, 0.88235295],\n",
       "          [0.94509804, 0.94509804, 0.93333334]],\n",
       " \n",
       "         [[0.5372549 , 0.5176471 , 0.49411765],\n",
       "          [0.50980395, 0.49803922, 0.47058824],\n",
       "          [0.49019608, 0.4745098 , 0.4509804 ],\n",
       "          ...,\n",
       "          [0.70980394, 0.7058824 , 0.69803923],\n",
       "          [0.7921569 , 0.7882353 , 0.7764706 ],\n",
       "          [0.83137256, 0.827451  , 0.8117647 ]],\n",
       " \n",
       "         [[0.47843137, 0.46666667, 0.44705883],\n",
       "          [0.4627451 , 0.45490196, 0.43137255],\n",
       "          [0.47058824, 0.45490196, 0.43529412],\n",
       "          ...,\n",
       "          [0.7019608 , 0.69411767, 0.6784314 ],\n",
       "          [0.6431373 , 0.6431373 , 0.63529414],\n",
       "          [0.6392157 , 0.6392157 , 0.6313726 ]]]], dtype=float32),\n",
       " array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.00392157],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.00392157],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.00392157],\n",
       "        [0.        , 0.00392157, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.00392157, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "prep_pixels(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 18:29:32.121352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-13 18:29:32.130101: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-13 18:29:32.131432: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-F5IN9DC): /proc/driver/nvidia/version does not exist\n",
      "2022-02-13 18:29:32.147295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f42342bcd30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_model():\n",
    "    model = Sequential([\n",
    "          # First Convolution Layer\n",
    "         Conv2D(32, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         Conv2D(32, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "         #Second Convolution Layer\n",
    "         Conv2D(64, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         Conv2D(64, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        #Third Convolution Layer\n",
    "         Conv2D(128, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         Conv2D(128, (3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'),\n",
    "         MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        #  Fully Connected Layer\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu', kernel_initializer='he_uniform'),\n",
    "        Dense(10, activation='softmax')])\n",
    " \n",
    " \n",
    "\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  \n",
    "    return model\n",
    "    \n",
    "define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
    "    # save model\n",
    "    model.save('cifar_final_model.h5')\n",
    "\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fbcb25ffd1e704b77e766f8f15869059d849d69d6a71e37721ac89c2bbcb90f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
